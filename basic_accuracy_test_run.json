{
    "report_metadata": {
        "title": "Evaluation Report",
        "generation_timestamp": "2025-04-23 14:51:03",
        "format": "json"
    },
    "evaluation_results": {
        "accuracy": 0.5,
        "precision": 0.5384615384615384,
        "recall": 0.5185185185185185,
        "f1_score": 0.5283018867924528,
        "visualizations": {
            "confusion_matrix_plot": "basic_accuracy_test_run_confusion_matrix.png"
        },
        "run_context": {
            "simulation_config": {
                "run_name": "basic_accuracy_test_run",
                "data_source": "synthetic",
                "metrics_to_run": [
                    "accuracy",
                    "precision",
                    "recall",
                    "f1_score"
                ],
                "reporting_formats": [
                    "markdown",
                    "json",
                    "html"
                ],
                "alert_rules": [
                    {
                        "metric_path": "accuracy",
                        "condition": "<",
                        "threshold": 0.7
                    },
                    {
                        "metric_path": "precision",
                        "condition": "<=",
                        "threshold": 0.6
                    }
                ]
            }
        }
    }
}